{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a051b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071a9c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f6b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\mlops-series\\mlops-mlflow\\mlfvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc58814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0e4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bb9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51efa0e",
   "metadata": {},
   "source": [
    "# infer signature -  important for inferencing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c5b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fcff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set tracking URI\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5586b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aba1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.load_wine(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb79b6",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffce3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ff7228",
   "metadata": {},
   "source": [
    "# Model hyperparameters in Randomforestclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "934f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a841eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 50,\n",
    "    \"criterion\": 'gini',\n",
    "    \"max_depth\": 5,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "613ea743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5487b284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':      alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       " 0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       " 1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       " 2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       " 3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       " 4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       " ..       ...         ...   ...                ...        ...            ...   \n",
       " 173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       " 174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       " 175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       " 176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       " 177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       " \n",
       "      flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       " 0          3.06                  0.28             2.29             5.64  1.04   \n",
       " 1          2.76                  0.26             1.28             4.38  1.05   \n",
       " 2          3.24                  0.30             2.81             5.68  1.03   \n",
       " 3          3.49                  0.24             2.18             7.80  0.86   \n",
       " 4          2.69                  0.39             1.82             4.32  1.04   \n",
       " ..          ...                   ...              ...              ...   ...   \n",
       " 173        0.61                  0.52             1.06             7.70  0.64   \n",
       " 174        0.75                  0.43             1.41             7.30  0.70   \n",
       " 175        0.69                  0.43             1.35            10.20  0.59   \n",
       " 176        0.68                  0.53             1.46             9.30  0.60   \n",
       " 177        0.76                  0.56             1.35             9.20  0.61   \n",
       " \n",
       "      od280/od315_of_diluted_wines  proline  \n",
       " 0                            3.92   1065.0  \n",
       " 1                            3.40   1050.0  \n",
       " 2                            3.17   1185.0  \n",
       " 3                            3.45   1480.0  \n",
       " 4                            2.93    735.0  \n",
       " ..                            ...      ...  \n",
       " 173                          1.74    740.0  \n",
       " 174                          1.56    750.0  \n",
       " 175                          1.56    835.0  \n",
       " 176                          1.62    840.0  \n",
       " 177                          1.60    560.0  \n",
       " \n",
       " [178 rows x 13 columns],\n",
       " 'target': 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 173    2\n",
       " 174    2\n",
       " 175    2\n",
       " 176    2\n",
       " 177    2\n",
       " Name: target, Length: 178, dtype: int64,\n",
       " 'frame':      alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       " 0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       " 1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       " 2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       " 3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       " 4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       " ..       ...         ...   ...                ...        ...            ...   \n",
       " 173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       " 174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       " 175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       " 176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       " 177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       " \n",
       "      flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       " 0          3.06                  0.28             2.29             5.64  1.04   \n",
       " 1          2.76                  0.26             1.28             4.38  1.05   \n",
       " 2          3.24                  0.30             2.81             5.68  1.03   \n",
       " 3          3.49                  0.24             2.18             7.80  0.86   \n",
       " 4          2.69                  0.39             1.82             4.32  1.04   \n",
       " ..          ...                   ...              ...              ...   ...   \n",
       " 173        0.61                  0.52             1.06             7.70  0.64   \n",
       " 174        0.75                  0.43             1.41             7.30  0.70   \n",
       " 175        0.69                  0.43             1.35            10.20  0.59   \n",
       " 176        0.68                  0.53             1.46             9.30  0.60   \n",
       " 177        0.76                  0.56             1.35             9.20  0.61   \n",
       " \n",
       "      od280/od315_of_diluted_wines  proline  target  \n",
       " 0                            3.92   1065.0       0  \n",
       " 1                            3.40   1050.0       0  \n",
       " 2                            3.17   1185.0       0  \n",
       " 3                            3.45   1480.0       0  \n",
       " 4                            2.93    735.0       0  \n",
       " ..                            ...      ...     ...  \n",
       " 173                          1.74    740.0       2  \n",
       " 174                          1.56    750.0       2  \n",
       " 175                          1.56    835.0       2  \n",
       " 176                          1.62    840.0       2  \n",
       " 177                          1.60    560.0       2  \n",
       " \n",
       " [178 rows x 14 columns],\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 178\\n:Number of Attributes: 13 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - Alcohol\\n    - Malic acid\\n    - Ash\\n    - Alcalinity of ash\\n    - Magnesium\\n    - Total phenols\\n    - Flavanoids\\n    - Nonflavanoid phenols\\n    - Proanthocyanins\\n    - Color intensity\\n    - Hue\\n    - OD280/OD315 of diluted wines\\n    - Proline\\n    - class:\\n        - class_0\\n        - class_1\\n        - class_2\\n\\n:Summary Statistics:\\n\\n============================= ==== ===== ======= =====\\n                                Min   Max   Mean     SD\\n============================= ==== ===== ======= =====\\nAlcohol:                      11.0  14.8    13.0   0.8\\nMalic Acid:                   0.74  5.80    2.34  1.12\\nAsh:                          1.36  3.23    2.36  0.27\\nAlcalinity of Ash:            10.6  30.0    19.5   3.3\\nMagnesium:                    70.0 162.0    99.7  14.3\\nTotal Phenols:                0.98  3.88    2.29  0.63\\nFlavanoids:                   0.34  5.08    2.03  1.00\\nNonflavanoid Phenols:         0.13  0.66    0.36  0.12\\nProanthocyanins:              0.41  3.58    1.59  0.57\\nColour Intensity:              1.3  13.0     5.1   2.3\\nHue:                          0.48  1.71    0.96  0.23\\nOD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\nProline:                       278  1680     746   315\\n============================= ==== ===== ======= =====\\n\\n:Missing Attribute Values: None\\n:Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners:\\n\\nForina, M. et al, PARVUS -\\nAn Extendible Package for Data Exploration, Classification and Correlation.\\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science.\\n\\n.. dropdown:: References\\n\\n    (1) S. Aeberhard, D. Coomans and O. de Vel,\\n    Comparison of Classifiers in High Dimensional Settings,\\n    Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\\n    Mathematics and Statistics, James Cook University of North Queensland.\\n    (Also submitted to Technometrics).\\n\\n    The data was used with many others for comparing various\\n    classifiers. The classes are separable, though only RDA\\n    has achieved 100% correct classification.\\n    (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\\n    (All results using the leave-one-out technique)\\n\\n    (2) S. Aeberhard, D. Coomans and O. de Vel,\\n    \"THE CLASSIFICATION PERFORMANCE OF RDA\"\\n    Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\\n    Mathematics and Statistics, James Cook University of North Queensland.\\n    (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0aceed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6c9acaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, n_estimators=50, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=5, n_estimators=50, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=50, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(**params)\n",
    "rf.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a256cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91a11794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 1, 0, 1, 2, 1, 2, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 2, 2, 2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 2, 2, 1, 2, 0, 1, 1, 1,\n",
       "       2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60b99b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2eb84940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bdbb4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a045f93",
   "metadata": {},
   "source": [
    "## MLFLow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9349ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc66cfb",
   "metadata": {},
   "source": [
    "*create a new experiment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efed70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'WineQualityRandomForestModel' already exists. Creating a new version of this model...\n",
      "2025/05/31 15:24:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: WineQualityRandomForestModel, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run popular-grouse-937 at: http://127.0.0.1:5000/#/experiments/545408099770630109/runs/692bed3b400c4e258178e4d220db088f\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/545408099770630109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'WineQualityRandomForestModel'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine_rf_experiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    #log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    #log accuracy metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc) # Convert to list for logging\n",
    "    \n",
    "    #Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Model Training\", \"Using a model = RandomForestClassifier\")\n",
    "    \n",
    "    ## Infer the model signature\n",
    "    signature = infer_signature(X_train, rf.predict(X_train))\n",
    "    \n",
    "    #log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        rf,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"WineQualityRandomForestModel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f17616ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/692bed3b400c4e258178e4d220db088f/model'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b2f8f",
   "metadata": {},
   "source": [
    "# Method 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def9582",
   "metadata": {},
   "source": [
    "# Inferencing and Validating before Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99c2cd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/692bed3b400c4e258178e4d220db088f/model'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee5a5ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2, 0, 1, 0, 0, 2, 2, 1, 1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 0,\n",
       "       2, 0, 0, 1, 2, 1, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1,\n",
       "       1, 1, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1,\n",
       "       1, 0, 0, 2, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       1, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0,\n",
       "       2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 0, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "\n",
    "model_uri = 'runs:/692bed3b400c4e258178e4d220db088f/model'\n",
    "# The model is logged with an input example\n",
    "serving_payload = \"\"\" {\n",
    "    \"inputs\": [\n",
    "  [\n",
    "    13.16,\n",
    "    2.36,\n",
    "    2.67,\n",
    "    18.6,\n",
    "    101,\n",
    "    2.8,\n",
    "    3.24,\n",
    "    0.3,\n",
    "    2.81,\n",
    "    5.68,\n",
    "    1.03,\n",
    "    3.17,\n",
    "    1185\n",
    "  ],\n",
    "  [\n",
    "    12.08,\n",
    "    2.08,\n",
    "    1.7,\n",
    "    17.5,\n",
    "    97,\n",
    "    2.23,\n",
    "    2.17,\n",
    "    0.26,\n",
    "    1.4,\n",
    "    3.3,\n",
    "    1.27,\n",
    "    2.96,\n",
    "    710\n",
    "  ],\n",
    "  [\n",
    "    12.42,\n",
    "    4.43,\n",
    "    2.73,\n",
    "    26.5,\n",
    "    102,\n",
    "    2.2,\n",
    "    2.13,\n",
    "    0.43,\n",
    "    1.71,\n",
    "    2.08,\n",
    "    0.92,\n",
    "    3.12,\n",
    "    365\n",
    "  ],\n",
    "  [\n",
    "    12.58,\n",
    "    1.29,\n",
    "    2.1,\n",
    "    20,\n",
    "    103,\n",
    "    1.48,\n",
    "    0.58,\n",
    "    0.53,\n",
    "    1.4,\n",
    "    7.6,\n",
    "    0.58,\n",
    "    1.55,\n",
    "    640\n",
    "  ],\n",
    "  [\n",
    "    13.83,\n",
    "    1.65,\n",
    "    2.6,\n",
    "    17.2,\n",
    "    94,\n",
    "    2.45,\n",
    "    2.99,\n",
    "    0.22,\n",
    "    2.29,\n",
    "    5.6,\n",
    "    1.24,\n",
    "    3.37,\n",
    "    1265\n",
    "  ],\n",
    "  [\n",
    "    13.03,\n",
    "    0.9,\n",
    "    1.71,\n",
    "    16,\n",
    "    86,\n",
    "    1.95,\n",
    "    2.03,\n",
    "    0.24,\n",
    "    1.46,\n",
    "    4.6,\n",
    "    1.19,\n",
    "    2.48,\n",
    "    392\n",
    "  ],\n",
    "  [\n",
    "    14.22,\n",
    "    1.7,\n",
    "    2.3,\n",
    "    16.3,\n",
    "    118,\n",
    "    3.2,\n",
    "    3,\n",
    "    0.26,\n",
    "    2.03,\n",
    "    6.38,\n",
    "    0.94,\n",
    "    3.31,\n",
    "    970\n",
    "  ],\n",
    "  [\n",
    "    13.39,\n",
    "    1.77,\n",
    "    2.62,\n",
    "    16.1,\n",
    "    93,\n",
    "    2.85,\n",
    "    2.94,\n",
    "    0.34,\n",
    "    1.45,\n",
    "    4.8,\n",
    "    0.92,\n",
    "    3.22,\n",
    "    1195\n",
    "  ],\n",
    "  [\n",
    "    13.23,\n",
    "    3.3,\n",
    "    2.28,\n",
    "    18.5,\n",
    "    98,\n",
    "    1.8,\n",
    "    0.83,\n",
    "    0.61,\n",
    "    1.87,\n",
    "    10.52,\n",
    "    0.56,\n",
    "    1.51,\n",
    "    675\n",
    "  ],\n",
    "  [\n",
    "    13.49,\n",
    "    3.59,\n",
    "    2.19,\n",
    "    19.5,\n",
    "    88,\n",
    "    1.62,\n",
    "    0.48,\n",
    "    0.58,\n",
    "    0.88,\n",
    "    5.7,\n",
    "    0.81,\n",
    "    1.82,\n",
    "    580\n",
    "  ],\n",
    "  [\n",
    "    12.51,\n",
    "    1.73,\n",
    "    1.98,\n",
    "    20.5,\n",
    "    85,\n",
    "    2.2,\n",
    "    1.92,\n",
    "    0.32,\n",
    "    1.48,\n",
    "    2.94,\n",
    "    1.04,\n",
    "    3.57,\n",
    "    672\n",
    "  ],\n",
    "  [\n",
    "    12.33,\n",
    "    0.99,\n",
    "    1.95,\n",
    "    14.8,\n",
    "    136,\n",
    "    1.9,\n",
    "    1.85,\n",
    "    0.35,\n",
    "    2.76,\n",
    "    3.4,\n",
    "    1.06,\n",
    "    2.31,\n",
    "    750\n",
    "  ],\n",
    "  [\n",
    "    13.28,\n",
    "    1.64,\n",
    "    2.84,\n",
    "    15.5,\n",
    "    110,\n",
    "    2.6,\n",
    "    2.68,\n",
    "    0.34,\n",
    "    1.36,\n",
    "    4.6,\n",
    "    1.09,\n",
    "    2.78,\n",
    "    880\n",
    "  ],\n",
    "  [\n",
    "    12.29,\n",
    "    2.83,\n",
    "    2.22,\n",
    "    18,\n",
    "    88,\n",
    "    2.45,\n",
    "    2.25,\n",
    "    0.25,\n",
    "    1.99,\n",
    "    2.15,\n",
    "    1.15,\n",
    "    3.3,\n",
    "    290\n",
    "  ],\n",
    "  [\n",
    "    13.71,\n",
    "    1.86,\n",
    "    2.36,\n",
    "    16.6,\n",
    "    101,\n",
    "    2.61,\n",
    "    2.88,\n",
    "    0.27,\n",
    "    1.69,\n",
    "    3.8,\n",
    "    1.11,\n",
    "    4,\n",
    "    1035\n",
    "  ],\n",
    "  [\n",
    "    13.88,\n",
    "    5.04,\n",
    "    2.23,\n",
    "    20,\n",
    "    80,\n",
    "    0.98,\n",
    "    0.34,\n",
    "    0.4,\n",
    "    0.68,\n",
    "    4.9,\n",
    "    0.58,\n",
    "    1.33,\n",
    "    415\n",
    "  ],\n",
    "  [\n",
    "    12.29,\n",
    "    1.41,\n",
    "    1.98,\n",
    "    16,\n",
    "    85,\n",
    "    2.55,\n",
    "    2.5,\n",
    "    0.29,\n",
    "    1.77,\n",
    "    2.9,\n",
    "    1.23,\n",
    "    2.74,\n",
    "    428\n",
    "  ],\n",
    "  [\n",
    "    12.21,\n",
    "    1.19,\n",
    "    1.75,\n",
    "    16.8,\n",
    "    151,\n",
    "    1.85,\n",
    "    1.28,\n",
    "    0.14,\n",
    "    2.5,\n",
    "    2.85,\n",
    "    1.28,\n",
    "    3.07,\n",
    "    718\n",
    "  ],\n",
    "  [\n",
    "    12.82,\n",
    "    3.37,\n",
    "    2.3,\n",
    "    19.5,\n",
    "    88,\n",
    "    1.48,\n",
    "    0.66,\n",
    "    0.4,\n",
    "    0.97,\n",
    "    10.26,\n",
    "    0.72,\n",
    "    1.75,\n",
    "    685\n",
    "  ],\n",
    "  [\n",
    "    14.12,\n",
    "    1.48,\n",
    "    2.32,\n",
    "    16.8,\n",
    "    95,\n",
    "    2.2,\n",
    "    2.43,\n",
    "    0.26,\n",
    "    1.57,\n",
    "    5,\n",
    "    1.17,\n",
    "    2.82,\n",
    "    1280\n",
    "  ],\n",
    "  [\n",
    "    14.39,\n",
    "    1.87,\n",
    "    2.45,\n",
    "    14.6,\n",
    "    96,\n",
    "    2.5,\n",
    "    2.52,\n",
    "    0.3,\n",
    "    1.98,\n",
    "    5.25,\n",
    "    1.02,\n",
    "    3.58,\n",
    "    1290\n",
    "  ],\n",
    "  [\n",
    "    13.3,\n",
    "    1.72,\n",
    "    2.14,\n",
    "    17,\n",
    "    94,\n",
    "    2.4,\n",
    "    2.19,\n",
    "    0.27,\n",
    "    1.35,\n",
    "    3.95,\n",
    "    1.02,\n",
    "    2.77,\n",
    "    1285\n",
    "  ],\n",
    "  [\n",
    "    12.25,\n",
    "    3.88,\n",
    "    2.2,\n",
    "    18.5,\n",
    "    112,\n",
    "    1.38,\n",
    "    0.78,\n",
    "    0.29,\n",
    "    1.14,\n",
    "    8.21,\n",
    "    0.65,\n",
    "    2,\n",
    "    855\n",
    "  ],\n",
    "  [\n",
    "    13.24,\n",
    "    2.59,\n",
    "    2.87,\n",
    "    21,\n",
    "    118,\n",
    "    2.8,\n",
    "    2.69,\n",
    "    0.39,\n",
    "    1.82,\n",
    "    4.32,\n",
    "    1.04,\n",
    "    2.93,\n",
    "    735\n",
    "  ],\n",
    "  [\n",
    "    13.68,\n",
    "    1.83,\n",
    "    2.36,\n",
    "    17.2,\n",
    "    104,\n",
    "    2.42,\n",
    "    2.69,\n",
    "    0.42,\n",
    "    1.97,\n",
    "    3.84,\n",
    "    1.23,\n",
    "    2.87,\n",
    "    990\n",
    "  ],\n",
    "  [\n",
    "    12.47,\n",
    "    1.52,\n",
    "    2.2,\n",
    "    19,\n",
    "    162,\n",
    "    2.5,\n",
    "    2.27,\n",
    "    0.32,\n",
    "    3.28,\n",
    "    2.6,\n",
    "    1.16,\n",
    "    2.63,\n",
    "    937\n",
    "  ],\n",
    "  [\n",
    "    12.2,\n",
    "    3.03,\n",
    "    2.32,\n",
    "    19,\n",
    "    96,\n",
    "    1.25,\n",
    "    0.49,\n",
    "    0.4,\n",
    "    0.73,\n",
    "    5.5,\n",
    "    0.66,\n",
    "    1.83,\n",
    "    510\n",
    "  ],\n",
    "  [\n",
    "    11.66,\n",
    "    1.88,\n",
    "    1.92,\n",
    "    16,\n",
    "    97,\n",
    "    1.61,\n",
    "    1.57,\n",
    "    0.34,\n",
    "    1.15,\n",
    "    3.8,\n",
    "    1.23,\n",
    "    2.14,\n",
    "    428\n",
    "  ],\n",
    "  [\n",
    "    14.1,\n",
    "    2.16,\n",
    "    2.3,\n",
    "    18,\n",
    "    105,\n",
    "    2.95,\n",
    "    3.32,\n",
    "    0.22,\n",
    "    2.38,\n",
    "    5.75,\n",
    "    1.25,\n",
    "    3.17,\n",
    "    1510\n",
    "  ],\n",
    "  [\n",
    "    12.87,\n",
    "    4.61,\n",
    "    2.48,\n",
    "    21.5,\n",
    "    86,\n",
    "    1.7,\n",
    "    0.65,\n",
    "    0.47,\n",
    "    0.86,\n",
    "    7.65,\n",
    "    0.54,\n",
    "    1.86,\n",
    "    625\n",
    "  ],\n",
    "  [\n",
    "    13.05,\n",
    "    5.8,\n",
    "    2.13,\n",
    "    21.5,\n",
    "    86,\n",
    "    2.62,\n",
    "    2.65,\n",
    "    0.3,\n",
    "    2.01,\n",
    "    2.6,\n",
    "    0.73,\n",
    "    3.1,\n",
    "    380\n",
    "  ],\n",
    "  [\n",
    "    14.23,\n",
    "    1.71,\n",
    "    2.43,\n",
    "    15.6,\n",
    "    127,\n",
    "    2.8,\n",
    "    3.06,\n",
    "    0.28,\n",
    "    2.29,\n",
    "    5.64,\n",
    "    1.04,\n",
    "    3.92,\n",
    "    1065\n",
    "  ],\n",
    "  [\n",
    "    13.52,\n",
    "    3.17,\n",
    "    2.72,\n",
    "    23.5,\n",
    "    97,\n",
    "    1.55,\n",
    "    0.52,\n",
    "    0.5,\n",
    "    0.55,\n",
    "    4.35,\n",
    "    0.89,\n",
    "    2.06,\n",
    "    520\n",
    "  ],\n",
    "  [\n",
    "    12.43,\n",
    "    1.53,\n",
    "    2.29,\n",
    "    21.5,\n",
    "    86,\n",
    "    2.74,\n",
    "    3.15,\n",
    "    0.39,\n",
    "    1.77,\n",
    "    3.94,\n",
    "    0.69,\n",
    "    2.84,\n",
    "    352\n",
    "  ],\n",
    "  [\n",
    "    12.17,\n",
    "    1.45,\n",
    "    2.53,\n",
    "    19,\n",
    "    104,\n",
    "    1.89,\n",
    "    1.75,\n",
    "    0.45,\n",
    "    1.03,\n",
    "    2.95,\n",
    "    1.45,\n",
    "    2.23,\n",
    "    355\n",
    "  ],\n",
    "  [\n",
    "    13.05,\n",
    "    1.77,\n",
    "    2.1,\n",
    "    17,\n",
    "    107,\n",
    "    3,\n",
    "    3,\n",
    "    0.28,\n",
    "    2.03,\n",
    "    5.04,\n",
    "    0.88,\n",
    "    3.35,\n",
    "    885\n",
    "  ],\n",
    "  [\n",
    "    11.81,\n",
    "    2.12,\n",
    "    2.74,\n",
    "    21.5,\n",
    "    134,\n",
    "    1.6,\n",
    "    0.99,\n",
    "    0.14,\n",
    "    1.56,\n",
    "    2.5,\n",
    "    0.95,\n",
    "    2.26,\n",
    "    625\n",
    "  ],\n",
    "  [\n",
    "    13.87,\n",
    "    1.9,\n",
    "    2.8,\n",
    "    19.4,\n",
    "    107,\n",
    "    2.95,\n",
    "    2.97,\n",
    "    0.37,\n",
    "    1.76,\n",
    "    4.5,\n",
    "    1.25,\n",
    "    3.4,\n",
    "    915\n",
    "  ],\n",
    "  [\n",
    "    13.56,\n",
    "    1.71,\n",
    "    2.31,\n",
    "    16.2,\n",
    "    117,\n",
    "    3.15,\n",
    "    3.29,\n",
    "    0.34,\n",
    "    2.34,\n",
    "    6.13,\n",
    "    0.95,\n",
    "    3.38,\n",
    "    795\n",
    "  ],\n",
    "  [\n",
    "    11.79,\n",
    "    2.13,\n",
    "    2.78,\n",
    "    28.5,\n",
    "    92,\n",
    "    2.13,\n",
    "    2.24,\n",
    "    0.58,\n",
    "    1.76,\n",
    "    3,\n",
    "    0.97,\n",
    "    2.44,\n",
    "    466\n",
    "  ],\n",
    "  [\n",
    "    13.05,\n",
    "    2.05,\n",
    "    3.22,\n",
    "    25,\n",
    "    124,\n",
    "    2.63,\n",
    "    2.68,\n",
    "    0.47,\n",
    "    1.92,\n",
    "    3.58,\n",
    "    1.13,\n",
    "    3.2,\n",
    "    830\n",
    "  ],\n",
    "  [\n",
    "    12.85,\n",
    "    1.6,\n",
    "    2.52,\n",
    "    17.8,\n",
    "    95,\n",
    "    2.48,\n",
    "    2.37,\n",
    "    0.26,\n",
    "    1.46,\n",
    "    3.93,\n",
    "    1.09,\n",
    "    3.63,\n",
    "    1015\n",
    "  ],\n",
    "  [\n",
    "    12.81,\n",
    "    2.31,\n",
    "    2.4,\n",
    "    24,\n",
    "    98,\n",
    "    1.15,\n",
    "    1.09,\n",
    "    0.27,\n",
    "    0.83,\n",
    "    5.7,\n",
    "    0.66,\n",
    "    1.36,\n",
    "    560\n",
    "  ],\n",
    "  [\n",
    "    12.72,\n",
    "    1.81,\n",
    "    2.2,\n",
    "    18.8,\n",
    "    86,\n",
    "    2.2,\n",
    "    2.53,\n",
    "    0.26,\n",
    "    1.77,\n",
    "    3.9,\n",
    "    1.16,\n",
    "    3.14,\n",
    "    714\n",
    "  ],\n",
    "  [\n",
    "    12.7,\n",
    "    3.87,\n",
    "    2.4,\n",
    "    23,\n",
    "    101,\n",
    "    2.83,\n",
    "    2.55,\n",
    "    0.43,\n",
    "    1.95,\n",
    "    2.57,\n",
    "    1.19,\n",
    "    3.13,\n",
    "    463\n",
    "  ],\n",
    "  [\n",
    "    11.84,\n",
    "    0.89,\n",
    "    2.58,\n",
    "    18,\n",
    "    94,\n",
    "    2.2,\n",
    "    2.21,\n",
    "    0.22,\n",
    "    2.35,\n",
    "    3.05,\n",
    "    0.79,\n",
    "    3.08,\n",
    "    520\n",
    "  ],\n",
    "  [\n",
    "    14.22,\n",
    "    3.99,\n",
    "    2.51,\n",
    "    13.2,\n",
    "    128,\n",
    "    3,\n",
    "    3.04,\n",
    "    0.2,\n",
    "    2.08,\n",
    "    5.1,\n",
    "    0.89,\n",
    "    3.53,\n",
    "    760\n",
    "  ],\n",
    "  [\n",
    "    12.6,\n",
    "    1.34,\n",
    "    1.9,\n",
    "    18.5,\n",
    "    88,\n",
    "    1.45,\n",
    "    1.36,\n",
    "    0.29,\n",
    "    1.35,\n",
    "    2.45,\n",
    "    1.04,\n",
    "    2.77,\n",
    "    562\n",
    "  ],\n",
    "  [\n",
    "    12.16,\n",
    "    1.61,\n",
    "    2.31,\n",
    "    22.8,\n",
    "    90,\n",
    "    1.78,\n",
    "    1.69,\n",
    "    0.43,\n",
    "    1.56,\n",
    "    2.45,\n",
    "    1.33,\n",
    "    2.26,\n",
    "    495\n",
    "  ],\n",
    "  [\n",
    "    11.45,\n",
    "    2.4,\n",
    "    2.42,\n",
    "    20,\n",
    "    96,\n",
    "    2.9,\n",
    "    2.79,\n",
    "    0.32,\n",
    "    1.83,\n",
    "    3.25,\n",
    "    0.8,\n",
    "    3.39,\n",
    "    625\n",
    "  ],\n",
    "  [\n",
    "    13.71,\n",
    "    5.65,\n",
    "    2.45,\n",
    "    20.5,\n",
    "    95,\n",
    "    1.68,\n",
    "    0.61,\n",
    "    0.52,\n",
    "    1.06,\n",
    "    7.7,\n",
    "    0.64,\n",
    "    1.74,\n",
    "    740\n",
    "  ],\n",
    "  [\n",
    "    12.85,\n",
    "    3.27,\n",
    "    2.58,\n",
    "    22,\n",
    "    106,\n",
    "    1.65,\n",
    "    0.6,\n",
    "    0.6,\n",
    "    0.96,\n",
    "    5.58,\n",
    "    0.87,\n",
    "    2.11,\n",
    "    570\n",
    "  ],\n",
    "  [\n",
    "    13.9,\n",
    "    1.68,\n",
    "    2.12,\n",
    "    16,\n",
    "    101,\n",
    "    3.1,\n",
    "    3.39,\n",
    "    0.21,\n",
    "    2.14,\n",
    "    6.1,\n",
    "    0.91,\n",
    "    3.33,\n",
    "    985\n",
    "  ],\n",
    "  [\n",
    "    11.62,\n",
    "    1.99,\n",
    "    2.28,\n",
    "    18,\n",
    "    98,\n",
    "    3.02,\n",
    "    2.26,\n",
    "    0.17,\n",
    "    1.35,\n",
    "    3.25,\n",
    "    1.16,\n",
    "    2.96,\n",
    "    345\n",
    "  ],\n",
    "  [\n",
    "    12.6,\n",
    "    2.46,\n",
    "    2.2,\n",
    "    18.5,\n",
    "    94,\n",
    "    1.62,\n",
    "    0.66,\n",
    "    0.63,\n",
    "    0.94,\n",
    "    7.1,\n",
    "    0.73,\n",
    "    1.58,\n",
    "    695\n",
    "  ],\n",
    "  [\n",
    "    13.45,\n",
    "    3.7,\n",
    "    2.6,\n",
    "    23,\n",
    "    111,\n",
    "    1.7,\n",
    "    0.92,\n",
    "    0.43,\n",
    "    1.46,\n",
    "    10.68,\n",
    "    0.85,\n",
    "    1.56,\n",
    "    695\n",
    "  ],\n",
    "  [\n",
    "    12.64,\n",
    "    1.36,\n",
    "    2.02,\n",
    "    16.8,\n",
    "    100,\n",
    "    2.02,\n",
    "    1.41,\n",
    "    0.53,\n",
    "    0.62,\n",
    "    5.75,\n",
    "    0.98,\n",
    "    1.59,\n",
    "    450\n",
    "  ],\n",
    "  [\n",
    "    12.99,\n",
    "    1.67,\n",
    "    2.6,\n",
    "    30,\n",
    "    139,\n",
    "    3.3,\n",
    "    2.89,\n",
    "    0.21,\n",
    "    1.96,\n",
    "    3.35,\n",
    "    1.31,\n",
    "    3.5,\n",
    "    985\n",
    "  ],\n",
    "  [\n",
    "    13.76,\n",
    "    1.53,\n",
    "    2.7,\n",
    "    19.5,\n",
    "    132,\n",
    "    2.95,\n",
    "    2.74,\n",
    "    0.5,\n",
    "    1.35,\n",
    "    5.4,\n",
    "    1.25,\n",
    "    3,\n",
    "    1235\n",
    "  ],\n",
    "  [\n",
    "    12.07,\n",
    "    2.16,\n",
    "    2.17,\n",
    "    21,\n",
    "    85,\n",
    "    2.6,\n",
    "    2.65,\n",
    "    0.37,\n",
    "    1.35,\n",
    "    2.76,\n",
    "    0.86,\n",
    "    3.28,\n",
    "    378\n",
    "  ],\n",
    "  [\n",
    "    12.7,\n",
    "    3.55,\n",
    "    2.36,\n",
    "    21.5,\n",
    "    106,\n",
    "    1.7,\n",
    "    1.2,\n",
    "    0.17,\n",
    "    0.84,\n",
    "    5,\n",
    "    0.78,\n",
    "    1.29,\n",
    "    600\n",
    "  ],\n",
    "  [\n",
    "    12.84,\n",
    "    2.96,\n",
    "    2.61,\n",
    "    24,\n",
    "    101,\n",
    "    2.32,\n",
    "    0.6,\n",
    "    0.53,\n",
    "    0.81,\n",
    "    4.92,\n",
    "    0.89,\n",
    "    2.15,\n",
    "    590\n",
    "  ],\n",
    "  [\n",
    "    13.67,\n",
    "    1.25,\n",
    "    1.92,\n",
    "    18,\n",
    "    94,\n",
    "    2.1,\n",
    "    1.79,\n",
    "    0.32,\n",
    "    0.73,\n",
    "    3.8,\n",
    "    1.23,\n",
    "    2.46,\n",
    "    630\n",
    "  ],\n",
    "  [\n",
    "    13.17,\n",
    "    2.59,\n",
    "    2.37,\n",
    "    20,\n",
    "    120,\n",
    "    1.65,\n",
    "    0.68,\n",
    "    0.53,\n",
    "    1.46,\n",
    "    9.3,\n",
    "    0.6,\n",
    "    1.62,\n",
    "    840\n",
    "  ],\n",
    "  [\n",
    "    11.76,\n",
    "    2.68,\n",
    "    2.92,\n",
    "    20,\n",
    "    103,\n",
    "    1.75,\n",
    "    2.03,\n",
    "    0.6,\n",
    "    1.05,\n",
    "    3.8,\n",
    "    1.23,\n",
    "    2.5,\n",
    "    607\n",
    "  ],\n",
    "  [\n",
    "    11.03,\n",
    "    1.51,\n",
    "    2.2,\n",
    "    21.5,\n",
    "    85,\n",
    "    2.46,\n",
    "    2.17,\n",
    "    0.52,\n",
    "    2.01,\n",
    "    1.9,\n",
    "    1.71,\n",
    "    2.87,\n",
    "    407\n",
    "  ],\n",
    "  [\n",
    "    12.42,\n",
    "    2.55,\n",
    "    2.27,\n",
    "    22,\n",
    "    90,\n",
    "    1.68,\n",
    "    1.84,\n",
    "    0.66,\n",
    "    1.42,\n",
    "    2.7,\n",
    "    0.86,\n",
    "    3.3,\n",
    "    315\n",
    "  ],\n",
    "  [\n",
    "    13.77,\n",
    "    1.9,\n",
    "    2.68,\n",
    "    17.1,\n",
    "    115,\n",
    "    3,\n",
    "    2.79,\n",
    "    0.39,\n",
    "    1.68,\n",
    "    6.3,\n",
    "    1.13,\n",
    "    2.93,\n",
    "    1375\n",
    "  ],\n",
    "  [\n",
    "    14.2,\n",
    "    1.76,\n",
    "    2.45,\n",
    "    15.2,\n",
    "    112,\n",
    "    3.27,\n",
    "    3.39,\n",
    "    0.34,\n",
    "    1.97,\n",
    "    6.75,\n",
    "    1.05,\n",
    "    2.85,\n",
    "    1450\n",
    "  ],\n",
    "  [\n",
    "    12.36,\n",
    "    3.83,\n",
    "    2.38,\n",
    "    21,\n",
    "    88,\n",
    "    2.3,\n",
    "    0.92,\n",
    "    0.5,\n",
    "    1.04,\n",
    "    7.65,\n",
    "    0.56,\n",
    "    1.58,\n",
    "    520\n",
    "  ],\n",
    "  [\n",
    "    14.37,\n",
    "    1.95,\n",
    "    2.5,\n",
    "    16.8,\n",
    "    113,\n",
    "    3.85,\n",
    "    3.49,\n",
    "    0.24,\n",
    "    2.18,\n",
    "    7.8,\n",
    "    0.86,\n",
    "    3.45,\n",
    "    1480\n",
    "  ],\n",
    "  [\n",
    "    13.73,\n",
    "    4.36,\n",
    "    2.26,\n",
    "    22.5,\n",
    "    88,\n",
    "    1.28,\n",
    "    0.47,\n",
    "    0.52,\n",
    "    1.15,\n",
    "    6.62,\n",
    "    0.78,\n",
    "    1.75,\n",
    "    520\n",
    "  ],\n",
    "  [\n",
    "    13.94,\n",
    "    1.73,\n",
    "    2.27,\n",
    "    17.4,\n",
    "    108,\n",
    "    2.88,\n",
    "    3.54,\n",
    "    0.32,\n",
    "    2.08,\n",
    "    8.9,\n",
    "    1.12,\n",
    "    3.1,\n",
    "    1260\n",
    "  ],\n",
    "  [\n",
    "    13.48,\n",
    "    1.81,\n",
    "    2.41,\n",
    "    20.5,\n",
    "    100,\n",
    "    2.7,\n",
    "    2.98,\n",
    "    0.26,\n",
    "    1.86,\n",
    "    5.1,\n",
    "    1.04,\n",
    "    3.47,\n",
    "    920\n",
    "  ],\n",
    "  [\n",
    "    12,\n",
    "    0.92,\n",
    "    2,\n",
    "    19,\n",
    "    86,\n",
    "    2.42,\n",
    "    2.26,\n",
    "    0.3,\n",
    "    1.43,\n",
    "    2.5,\n",
    "    1.38,\n",
    "    3.12,\n",
    "    278\n",
    "  ],\n",
    "  [\n",
    "    11.84,\n",
    "    2.89,\n",
    "    2.23,\n",
    "    18,\n",
    "    112,\n",
    "    1.72,\n",
    "    1.32,\n",
    "    0.43,\n",
    "    0.95,\n",
    "    2.65,\n",
    "    0.96,\n",
    "    2.52,\n",
    "    500\n",
    "  ],\n",
    "  [\n",
    "    13.51,\n",
    "    1.8,\n",
    "    2.65,\n",
    "    19,\n",
    "    110,\n",
    "    2.35,\n",
    "    2.53,\n",
    "    0.29,\n",
    "    1.54,\n",
    "    4.2,\n",
    "    1.1,\n",
    "    2.87,\n",
    "    1095\n",
    "  ],\n",
    "  [\n",
    "    14.38,\n",
    "    3.59,\n",
    "    2.28,\n",
    "    16,\n",
    "    102,\n",
    "    3.25,\n",
    "    3.17,\n",
    "    0.27,\n",
    "    2.19,\n",
    "    4.9,\n",
    "    1.04,\n",
    "    3.44,\n",
    "    1065\n",
    "  ],\n",
    "  [\n",
    "    14.06,\n",
    "    2.15,\n",
    "    2.61,\n",
    "    17.6,\n",
    "    121,\n",
    "    2.6,\n",
    "    2.51,\n",
    "    0.31,\n",
    "    1.25,\n",
    "    5.05,\n",
    "    1.06,\n",
    "    3.58,\n",
    "    1295\n",
    "  ],\n",
    "  [\n",
    "    11.87,\n",
    "    4.31,\n",
    "    2.39,\n",
    "    21,\n",
    "    82,\n",
    "    2.86,\n",
    "    3.03,\n",
    "    0.21,\n",
    "    2.91,\n",
    "    2.8,\n",
    "    0.75,\n",
    "    3.64,\n",
    "    380\n",
    "  ],\n",
    "  [\n",
    "    13.24,\n",
    "    3.98,\n",
    "    2.29,\n",
    "    17.5,\n",
    "    103,\n",
    "    2.64,\n",
    "    2.63,\n",
    "    0.32,\n",
    "    1.66,\n",
    "    4.36,\n",
    "    0.82,\n",
    "    3,\n",
    "    680\n",
    "  ],\n",
    "  [\n",
    "    12.29,\n",
    "    1.61,\n",
    "    2.21,\n",
    "    20.4,\n",
    "    103,\n",
    "    1.1,\n",
    "    1.02,\n",
    "    0.37,\n",
    "    1.46,\n",
    "    3.05,\n",
    "    0.906,\n",
    "    1.82,\n",
    "    870\n",
    "  ],\n",
    "  [\n",
    "    12.25,\n",
    "    4.72,\n",
    "    2.54,\n",
    "    21,\n",
    "    89,\n",
    "    1.38,\n",
    "    0.47,\n",
    "    0.53,\n",
    "    0.8,\n",
    "    3.85,\n",
    "    0.75,\n",
    "    1.27,\n",
    "    720\n",
    "  ],\n",
    "  [\n",
    "    11.46,\n",
    "    3.74,\n",
    "    1.82,\n",
    "    19.5,\n",
    "    107,\n",
    "    3.18,\n",
    "    2.58,\n",
    "    0.24,\n",
    "    3.58,\n",
    "    2.9,\n",
    "    0.75,\n",
    "    2.81,\n",
    "    562\n",
    "  ],\n",
    "  [\n",
    "    12,\n",
    "    1.51,\n",
    "    2.42,\n",
    "    22,\n",
    "    86,\n",
    "    1.45,\n",
    "    1.25,\n",
    "    0.5,\n",
    "    1.63,\n",
    "    3.6,\n",
    "    1.05,\n",
    "    2.65,\n",
    "    450\n",
    "  ],\n",
    "  [\n",
    "    13.05,\n",
    "    3.86,\n",
    "    2.32,\n",
    "    22.5,\n",
    "    85,\n",
    "    1.65,\n",
    "    1.59,\n",
    "    0.61,\n",
    "    1.62,\n",
    "    4.8,\n",
    "    0.84,\n",
    "    2.01,\n",
    "    515\n",
    "  ],\n",
    "  [\n",
    "    13.84,\n",
    "    4.12,\n",
    "    2.38,\n",
    "    19.5,\n",
    "    89,\n",
    "    1.8,\n",
    "    0.83,\n",
    "    0.48,\n",
    "    1.56,\n",
    "    9.01,\n",
    "    0.57,\n",
    "    1.64,\n",
    "    480\n",
    "  ],\n",
    "  [\n",
    "    13.69,\n",
    "    3.26,\n",
    "    2.54,\n",
    "    20,\n",
    "    107,\n",
    "    1.83,\n",
    "    0.56,\n",
    "    0.5,\n",
    "    0.8,\n",
    "    5.88,\n",
    "    0.96,\n",
    "    1.82,\n",
    "    680\n",
    "  ],\n",
    "  [\n",
    "    12.08,\n",
    "    1.33,\n",
    "    2.3,\n",
    "    23.6,\n",
    "    70,\n",
    "    2.2,\n",
    "    1.59,\n",
    "    0.42,\n",
    "    1.38,\n",
    "    1.74,\n",
    "    1.07,\n",
    "    3.21,\n",
    "    625\n",
    "  ],\n",
    "  [\n",
    "    14.83,\n",
    "    1.64,\n",
    "    2.17,\n",
    "    14,\n",
    "    97,\n",
    "    2.8,\n",
    "    2.98,\n",
    "    0.29,\n",
    "    1.98,\n",
    "    5.2,\n",
    "    1.08,\n",
    "    2.85,\n",
    "    1045\n",
    "  ],\n",
    "  [\n",
    "    14.75,\n",
    "    1.73,\n",
    "    2.39,\n",
    "    11.4,\n",
    "    91,\n",
    "    3.1,\n",
    "    3.69,\n",
    "    0.43,\n",
    "    2.81,\n",
    "    5.4,\n",
    "    1.25,\n",
    "    2.73,\n",
    "    1150\n",
    "  ],\n",
    "  [\n",
    "    12.37,\n",
    "    0.94,\n",
    "    1.36,\n",
    "    10.6,\n",
    "    88,\n",
    "    1.98,\n",
    "    0.57,\n",
    "    0.28,\n",
    "    0.42,\n",
    "    1.95,\n",
    "    1.05,\n",
    "    1.82,\n",
    "    520\n",
    "  ],\n",
    "  [\n",
    "    13.11,\n",
    "    1.9,\n",
    "    2.75,\n",
    "    25.5,\n",
    "    116,\n",
    "    2.2,\n",
    "    1.28,\n",
    "    0.26,\n",
    "    1.56,\n",
    "    7.1,\n",
    "    0.61,\n",
    "    1.33,\n",
    "    425\n",
    "  ],\n",
    "  [\n",
    "    12.88,\n",
    "    2.99,\n",
    "    2.4,\n",
    "    20,\n",
    "    104,\n",
    "    1.3,\n",
    "    1.22,\n",
    "    0.24,\n",
    "    0.83,\n",
    "    5.4,\n",
    "    0.74,\n",
    "    1.42,\n",
    "    530\n",
    "  ],\n",
    "  [\n",
    "    13.83,\n",
    "    1.57,\n",
    "    2.62,\n",
    "    20,\n",
    "    115,\n",
    "    2.95,\n",
    "    3.4,\n",
    "    0.4,\n",
    "    1.72,\n",
    "    6.6,\n",
    "    1.13,\n",
    "    2.57,\n",
    "    1130\n",
    "  ],\n",
    "  [\n",
    "    13.49,\n",
    "    1.66,\n",
    "    2.24,\n",
    "    24,\n",
    "    87,\n",
    "    1.88,\n",
    "    1.84,\n",
    "    0.27,\n",
    "    1.03,\n",
    "    3.74,\n",
    "    0.98,\n",
    "    2.78,\n",
    "    472\n",
    "  ],\n",
    "  [\n",
    "    13.17,\n",
    "    5.19,\n",
    "    2.32,\n",
    "    22,\n",
    "    93,\n",
    "    1.74,\n",
    "    0.63,\n",
    "    0.61,\n",
    "    1.55,\n",
    "    7.9,\n",
    "    0.6,\n",
    "    1.48,\n",
    "    725\n",
    "  ],\n",
    "  [\n",
    "    12.51,\n",
    "    1.24,\n",
    "    2.25,\n",
    "    17.5,\n",
    "    85,\n",
    "    2,\n",
    "    0.58,\n",
    "    0.6,\n",
    "    1.25,\n",
    "    5.45,\n",
    "    0.75,\n",
    "    1.51,\n",
    "    650\n",
    "  ],\n",
    "  [\n",
    "    13.32,\n",
    "    3.24,\n",
    "    2.38,\n",
    "    21.5,\n",
    "    92,\n",
    "    1.93,\n",
    "    0.76,\n",
    "    0.45,\n",
    "    1.25,\n",
    "    8.42,\n",
    "    0.55,\n",
    "    1.62,\n",
    "    650\n",
    "  ],\n",
    "  [\n",
    "    12.96,\n",
    "    3.45,\n",
    "    2.35,\n",
    "    18.5,\n",
    "    106,\n",
    "    1.39,\n",
    "    0.7,\n",
    "    0.4,\n",
    "    0.94,\n",
    "    5.28,\n",
    "    0.68,\n",
    "    1.75,\n",
    "    675\n",
    "  ],\n",
    "  [\n",
    "    12.37,\n",
    "    1.13,\n",
    "    2.16,\n",
    "    19,\n",
    "    87,\n",
    "    3.5,\n",
    "    3.1,\n",
    "    0.19,\n",
    "    1.87,\n",
    "    4.45,\n",
    "    1.22,\n",
    "    2.87,\n",
    "    420\n",
    "  ],\n",
    "  [\n",
    "    13.74,\n",
    "    1.67,\n",
    "    2.25,\n",
    "    16.4,\n",
    "    118,\n",
    "    2.6,\n",
    "    2.9,\n",
    "    0.21,\n",
    "    1.62,\n",
    "    5.85,\n",
    "    0.92,\n",
    "    3.2,\n",
    "    1060\n",
    "  ],\n",
    "  [\n",
    "    12.72,\n",
    "    1.75,\n",
    "    2.28,\n",
    "    22.5,\n",
    "    84,\n",
    "    1.38,\n",
    "    1.76,\n",
    "    0.48,\n",
    "    1.63,\n",
    "    3.3,\n",
    "    0.88,\n",
    "    2.42,\n",
    "    488\n",
    "  ],\n",
    "  [\n",
    "    13.05,\n",
    "    1.73,\n",
    "    2.04,\n",
    "    12.4,\n",
    "    92,\n",
    "    2.72,\n",
    "    3.27,\n",
    "    0.17,\n",
    "    2.91,\n",
    "    7.2,\n",
    "    1.12,\n",
    "    2.91,\n",
    "    1150\n",
    "  ],\n",
    "  [\n",
    "    13.27,\n",
    "    4.28,\n",
    "    2.26,\n",
    "    20,\n",
    "    120,\n",
    "    1.59,\n",
    "    0.69,\n",
    "    0.43,\n",
    "    1.35,\n",
    "    10.2,\n",
    "    0.59,\n",
    "    1.56,\n",
    "    835\n",
    "  ],\n",
    "  [\n",
    "    13.72,\n",
    "    1.43,\n",
    "    2.5,\n",
    "    16.7,\n",
    "    108,\n",
    "    3.4,\n",
    "    3.67,\n",
    "    0.19,\n",
    "    2.04,\n",
    "    6.8,\n",
    "    0.89,\n",
    "    2.87,\n",
    "    1285\n",
    "  ],\n",
    "  [\n",
    "    14.1,\n",
    "    2.02,\n",
    "    2.4,\n",
    "    18.8,\n",
    "    103,\n",
    "    2.75,\n",
    "    2.92,\n",
    "    0.32,\n",
    "    2.38,\n",
    "    6.2,\n",
    "    1.07,\n",
    "    2.75,\n",
    "    1060\n",
    "  ],\n",
    "  [\n",
    "    11.64,\n",
    "    2.06,\n",
    "    2.46,\n",
    "    21.6,\n",
    "    84,\n",
    "    1.95,\n",
    "    1.69,\n",
    "    0.48,\n",
    "    1.35,\n",
    "    2.8,\n",
    "    1,\n",
    "    2.75,\n",
    "    680\n",
    "  ],\n",
    "  [\n",
    "    12.93,\n",
    "    3.8,\n",
    "    2.65,\n",
    "    18.6,\n",
    "    102,\n",
    "    2.41,\n",
    "    2.41,\n",
    "    0.25,\n",
    "    1.98,\n",
    "    4.5,\n",
    "    1.03,\n",
    "    3.52,\n",
    "    770\n",
    "  ],\n",
    "  [\n",
    "    13.29,\n",
    "    1.97,\n",
    "    2.68,\n",
    "    16.8,\n",
    "    102,\n",
    "    3,\n",
    "    3.23,\n",
    "    0.31,\n",
    "    1.66,\n",
    "    6,\n",
    "    1.07,\n",
    "    2.84,\n",
    "    1270\n",
    "  ],\n",
    "  [\n",
    "    14.16,\n",
    "    2.51,\n",
    "    2.48,\n",
    "    20,\n",
    "    91,\n",
    "    1.68,\n",
    "    0.7,\n",
    "    0.44,\n",
    "    1.24,\n",
    "    9.7,\n",
    "    0.62,\n",
    "    1.71,\n",
    "    660\n",
    "  ],\n",
    "  [\n",
    "    12.04,\n",
    "    4.3,\n",
    "    2.38,\n",
    "    22,\n",
    "    80,\n",
    "    2.1,\n",
    "    1.75,\n",
    "    0.42,\n",
    "    1.35,\n",
    "    2.6,\n",
    "    0.79,\n",
    "    2.57,\n",
    "    580\n",
    "  ],\n",
    "  [\n",
    "    13.05,\n",
    "    1.65,\n",
    "    2.55,\n",
    "    18,\n",
    "    98,\n",
    "    2.45,\n",
    "    2.43,\n",
    "    0.29,\n",
    "    1.44,\n",
    "    4.25,\n",
    "    1.12,\n",
    "    2.51,\n",
    "    1105\n",
    "  ],\n",
    "  [\n",
    "    12.45,\n",
    "    3.03,\n",
    "    2.64,\n",
    "    27,\n",
    "    97,\n",
    "    1.9,\n",
    "    0.58,\n",
    "    0.63,\n",
    "    1.14,\n",
    "    7.5,\n",
    "    0.67,\n",
    "    1.73,\n",
    "    880\n",
    "  ],\n",
    "  [\n",
    "    13.58,\n",
    "    2.58,\n",
    "    2.69,\n",
    "    24.5,\n",
    "    105,\n",
    "    1.55,\n",
    "    0.84,\n",
    "    0.39,\n",
    "    1.54,\n",
    "    8.66,\n",
    "    0.74,\n",
    "    1.8,\n",
    "    750\n",
    "  ],\n",
    "  [\n",
    "    13.2,\n",
    "    1.78,\n",
    "    2.14,\n",
    "    11.2,\n",
    "    100,\n",
    "    2.65,\n",
    "    2.76,\n",
    "    0.26,\n",
    "    1.28,\n",
    "    4.38,\n",
    "    1.05,\n",
    "    3.4,\n",
    "    1050\n",
    "  ],\n",
    "  [\n",
    "    13.82,\n",
    "    1.75,\n",
    "    2.42,\n",
    "    14,\n",
    "    111,\n",
    "    3.88,\n",
    "    3.74,\n",
    "    0.32,\n",
    "    1.87,\n",
    "    7.05,\n",
    "    1.01,\n",
    "    3.26,\n",
    "    1190\n",
    "  ],\n",
    "  [\n",
    "    13.08,\n",
    "    3.9,\n",
    "    2.36,\n",
    "    21.5,\n",
    "    113,\n",
    "    1.41,\n",
    "    1.39,\n",
    "    0.34,\n",
    "    1.14,\n",
    "    9.4,\n",
    "    0.57,\n",
    "    1.33,\n",
    "    550\n",
    "  ],\n",
    "  [\n",
    "    12.86,\n",
    "    1.35,\n",
    "    2.32,\n",
    "    18,\n",
    "    122,\n",
    "    1.51,\n",
    "    1.25,\n",
    "    0.21,\n",
    "    0.94,\n",
    "    4.1,\n",
    "    0.76,\n",
    "    1.29,\n",
    "    630\n",
    "  ],\n",
    "  [\n",
    "    12.79,\n",
    "    2.67,\n",
    "    2.48,\n",
    "    22,\n",
    "    112,\n",
    "    1.48,\n",
    "    1.36,\n",
    "    0.24,\n",
    "    1.26,\n",
    "    10.8,\n",
    "    0.48,\n",
    "    1.47,\n",
    "    480\n",
    "  ],\n",
    "  [\n",
    "    11.82,\n",
    "    1.72,\n",
    "    1.88,\n",
    "    19.5,\n",
    "    86,\n",
    "    2.5,\n",
    "    1.64,\n",
    "    0.37,\n",
    "    1.42,\n",
    "    2.06,\n",
    "    0.94,\n",
    "    2.44,\n",
    "    415\n",
    "  ],\n",
    "  [\n",
    "    12.29,\n",
    "    3.17,\n",
    "    2.21,\n",
    "    18,\n",
    "    88,\n",
    "    2.85,\n",
    "    2.99,\n",
    "    0.45,\n",
    "    2.81,\n",
    "    2.3,\n",
    "    1.42,\n",
    "    2.83,\n",
    "    406\n",
    "  ],\n",
    "  [\n",
    "    11.82,\n",
    "    1.47,\n",
    "    1.99,\n",
    "    20.8,\n",
    "    86,\n",
    "    1.98,\n",
    "    1.6,\n",
    "    0.3,\n",
    "    1.53,\n",
    "    1.95,\n",
    "    0.95,\n",
    "    3.33,\n",
    "    495\n",
    "  ],\n",
    "  [\n",
    "    11.65,\n",
    "    1.67,\n",
    "    2.62,\n",
    "    26,\n",
    "    88,\n",
    "    1.92,\n",
    "    1.61,\n",
    "    0.4,\n",
    "    1.34,\n",
    "    2.6,\n",
    "    1.36,\n",
    "    3.21,\n",
    "    562\n",
    "  ],\n",
    "  [\n",
    "    11.96,\n",
    "    1.09,\n",
    "    2.3,\n",
    "    21,\n",
    "    101,\n",
    "    3.38,\n",
    "    2.14,\n",
    "    0.13,\n",
    "    1.65,\n",
    "    3.21,\n",
    "    0.99,\n",
    "    3.13,\n",
    "    886\n",
    "  ],\n",
    "  [\n",
    "    11.56,\n",
    "    2.05,\n",
    "    3.23,\n",
    "    28.5,\n",
    "    119,\n",
    "    3.18,\n",
    "    5.08,\n",
    "    0.47,\n",
    "    1.87,\n",
    "    6,\n",
    "    0.93,\n",
    "    3.69,\n",
    "    465\n",
    "  ],\n",
    "  [\n",
    "    14.13,\n",
    "    4.1,\n",
    "    2.74,\n",
    "    24.5,\n",
    "    96,\n",
    "    2.05,\n",
    "    0.76,\n",
    "    0.56,\n",
    "    1.35,\n",
    "    9.2,\n",
    "    0.61,\n",
    "    1.6,\n",
    "    560\n",
    "  ],\n",
    "  [\n",
    "    14.06,\n",
    "    1.63,\n",
    "    2.28,\n",
    "    16,\n",
    "    126,\n",
    "    3,\n",
    "    3.17,\n",
    "    0.24,\n",
    "    2.1,\n",
    "    5.65,\n",
    "    1.09,\n",
    "    3.71,\n",
    "    780\n",
    "  ],\n",
    "  [\n",
    "    13.86,\n",
    "    1.51,\n",
    "    2.67,\n",
    "    25,\n",
    "    86,\n",
    "    2.95,\n",
    "    2.86,\n",
    "    0.21,\n",
    "    1.87,\n",
    "    3.38,\n",
    "    1.36,\n",
    "    3.16,\n",
    "    410\n",
    "  ],\n",
    "  [\n",
    "    12.25,\n",
    "    1.73,\n",
    "    2.12,\n",
    "    19,\n",
    "    80,\n",
    "    1.65,\n",
    "    2.03,\n",
    "    0.37,\n",
    "    1.63,\n",
    "    3.4,\n",
    "    1,\n",
    "    3.17,\n",
    "    510\n",
    "  ],\n",
    "  [\n",
    "    14.38,\n",
    "    1.87,\n",
    "    2.38,\n",
    "    12,\n",
    "    102,\n",
    "    3.3,\n",
    "    3.64,\n",
    "    0.29,\n",
    "    2.96,\n",
    "    7.5,\n",
    "    1.2,\n",
    "    3,\n",
    "    1547\n",
    "  ],\n",
    "  [\n",
    "    12.69,\n",
    "    1.53,\n",
    "    2.26,\n",
    "    20.7,\n",
    "    80,\n",
    "    1.38,\n",
    "    1.46,\n",
    "    0.58,\n",
    "    1.62,\n",
    "    3.05,\n",
    "    0.96,\n",
    "    2.06,\n",
    "    495\n",
    "  ],\n",
    "  [\n",
    "    12.34,\n",
    "    2.45,\n",
    "    2.46,\n",
    "    21,\n",
    "    98,\n",
    "    2.56,\n",
    "    2.11,\n",
    "    0.34,\n",
    "    1.31,\n",
    "    2.8,\n",
    "    0.8,\n",
    "    3.38,\n",
    "    438\n",
    "  ]\n",
    "]\n",
    "    \n",
    "    \n",
    "}\"\"\"\n",
    "\n",
    "validate_serving_input(model_uri,serving_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e129dbc",
   "metadata": {},
   "source": [
    "# Method 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29446fd5",
   "metadata": {},
   "source": [
    "# load model back for prediction as a generic python function model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d90391e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2018b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "wine_features_name = datasets.load_wine().feature_names\n",
    "result = pd.DataFrame(X_test,columns=wine_features_name)\n",
    "result['actual_class'] = y_test\n",
    "result['predicted_class'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c01ecda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.21</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.44</td>\n",
       "      <td>18.9</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.240000</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.93</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.31</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.73</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.70</td>\n",
       "      <td>22.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.92</td>\n",
       "      <td>19.6</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.48</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.00</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.05</td>\n",
       "      <td>564.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.61</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.70</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.26</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.36</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.47</td>\n",
       "      <td>780.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.50</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>24.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.30</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.41</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.12</td>\n",
       "      <td>18.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.280000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.77</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.12</td>\n",
       "      <td>372.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.52</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.78</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.41</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.50</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.31</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>24.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.72</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.50</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.19</td>\n",
       "      <td>385.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.18</td>\n",
       "      <td>502.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.33</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.67</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>630.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.77</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.899999</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.63</td>\n",
       "      <td>470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>615.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.96</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.56</td>\n",
       "      <td>18.1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.08</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.30</td>\n",
       "      <td>678.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.27</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13.56</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.46</td>\n",
       "      <td>20.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.45</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>342.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.16</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.68</td>\n",
       "      <td>830.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13.58</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.36</td>\n",
       "      <td>19.1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>13.88</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.59</td>\n",
       "      <td>15.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>660.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.10</td>\n",
       "      <td>18.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.77</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>620.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13.07</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>15.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>12.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.94</td>\n",
       "      <td>19.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.02</td>\n",
       "      <td>312.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12.67</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.24</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.16</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.34</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>17.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.93</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13.62</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.05</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0     13.64        3.10  2.56               15.2      116.0           2.70   \n",
       "1     14.21        4.04  2.44               18.9      111.0           2.85   \n",
       "2     12.93        2.81  2.70               21.0       96.0           1.54   \n",
       "3     13.73        1.50  2.70               22.5      101.0           3.00   \n",
       "4     12.37        1.17  1.92               19.6       78.0           2.11   \n",
       "5     14.30        1.92  2.72               20.0      120.0           2.80   \n",
       "6     12.00        3.43  2.00               19.0       87.0           2.00   \n",
       "7     13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "8     11.61        1.35  2.70               20.0       94.0           2.74   \n",
       "9     13.36        2.56  2.35               20.0       89.0           1.40   \n",
       "10    13.50        1.81  2.61               20.0       96.0           2.53   \n",
       "11    13.50        3.12  2.62               24.0      123.0           1.40   \n",
       "12    13.41        3.84  2.12               18.8       90.0           2.45   \n",
       "13    12.77        3.43  1.98               16.0       80.0           1.63   \n",
       "14    13.63        1.81  2.70               17.2      112.0           2.85   \n",
       "15    12.52        2.43  2.17               21.0       88.0           2.55   \n",
       "16    11.41        0.74  2.50               21.0       88.0           2.48   \n",
       "17    12.08        1.13  2.51               24.0       78.0           2.00   \n",
       "18    13.86        1.35  2.27               16.0       98.0           2.98   \n",
       "19    12.08        1.39  2.50               22.5       84.0           2.56   \n",
       "20    14.19        1.59  2.48               16.5      108.0           3.30   \n",
       "21    13.11        1.01  1.70               15.0       78.0           2.98   \n",
       "22    12.33        1.10  2.28               16.0      101.0           2.05   \n",
       "23    13.40        4.60  2.86               25.0      112.0           1.98   \n",
       "24    12.77        2.39  2.28               19.5       86.0           1.39   \n",
       "25    13.78        2.76  2.30               22.0       90.0           1.35   \n",
       "26    12.42        1.61  2.19               22.5      108.0           2.00   \n",
       "27    12.37        1.21  2.56               18.1       98.0           2.42   \n",
       "28    12.08        1.83  2.32               18.5       81.0           1.60   \n",
       "29    13.56        1.73  2.46               20.5      116.0           2.96   \n",
       "30    14.02        1.68  2.21               16.0       96.0           2.65   \n",
       "31    12.37        1.63  2.30               24.5       88.0           2.22   \n",
       "32    13.16        3.57  2.15               21.0      102.0           1.50   \n",
       "33    13.58        1.66  2.36               19.1      106.0           2.86   \n",
       "34    13.75        1.73  2.41               16.0       89.0           2.60   \n",
       "35    13.88        1.89  2.59               15.0      101.0           3.25   \n",
       "36    14.34        1.68  2.70               25.0       98.0           2.80   \n",
       "37    12.53        5.51  2.64               25.0       96.0           1.79   \n",
       "38    12.37        1.07  2.10               18.5       88.0           3.52   \n",
       "39    13.48        1.67  2.64               22.5       89.0           2.60   \n",
       "40    13.07        1.50  2.10               15.5       98.0           2.40   \n",
       "41    12.22        1.29  1.94               19.0       92.0           2.36   \n",
       "42    12.67        0.98  2.24               18.0       99.0           2.20   \n",
       "43    13.34        0.94  2.36               17.0      110.0           2.53   \n",
       "44    13.62        4.95  2.35               20.0       92.0           2.00   \n",
       "\n",
       "    flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0         3.03                  0.17             1.66         5.100000  0.96   \n",
       "1         2.65                  0.30             1.25         5.240000  0.87   \n",
       "2         0.50                  0.53             0.75         4.600000  0.77   \n",
       "3         3.25                  0.29             2.38         5.700000  1.19   \n",
       "4         2.00                  0.27             1.04         4.680000  1.12   \n",
       "5         3.14                  0.33             1.97         6.200000  1.07   \n",
       "6         1.64                  0.37             1.87         1.280000  0.93   \n",
       "7         0.75                  0.43             1.41         7.300000  0.70   \n",
       "8         2.92                  0.29             2.49         2.650000  0.96   \n",
       "9         0.50                  0.37             0.64         5.600000  0.70   \n",
       "10        2.61                  0.28             1.66         3.520000  1.12   \n",
       "11        1.57                  0.22             1.25         8.600000  0.59   \n",
       "12        2.68                  0.27             1.48         4.280000  0.91   \n",
       "13        1.25                  0.43             0.83         3.400000  0.70   \n",
       "14        2.91                  0.30             1.46         7.300000  1.28   \n",
       "15        2.27                  0.26             1.22         2.000000  0.90   \n",
       "16        2.01                  0.42             1.44         3.080000  1.10   \n",
       "17        1.58                  0.40             1.40         2.200000  1.31   \n",
       "18        3.15                  0.22             1.85         7.220000  1.01   \n",
       "19        2.29                  0.43             1.04         2.900000  0.93   \n",
       "20        3.93                  0.32             1.86         8.700000  1.23   \n",
       "21        3.18                  0.26             2.28         5.300000  1.12   \n",
       "22        1.09                  0.63             0.41         3.270000  1.25   \n",
       "23        0.96                  0.27             1.11         8.500000  0.67   \n",
       "24        0.51                  0.48             0.64         9.899999  0.57   \n",
       "25        0.68                  0.41             1.03         9.580000  0.70   \n",
       "26        2.09                  0.34             1.61         2.060000  1.06   \n",
       "27        2.65                  0.37             2.08         4.600000  1.19   \n",
       "28        1.50                  0.52             1.64         2.400000  1.08   \n",
       "29        2.78                  0.20             2.45         6.250000  0.98   \n",
       "30        2.33                  0.26             1.98         4.700000  1.04   \n",
       "31        2.45                  0.40             1.90         2.120000  0.89   \n",
       "32        0.55                  0.43             1.30         4.000000  0.60   \n",
       "33        3.19                  0.22             1.95         6.900000  1.09   \n",
       "34        2.76                  0.29             1.81         5.600000  1.15   \n",
       "35        3.56                  0.17             1.70         5.430000  0.88   \n",
       "36        1.31                  0.53             2.70        13.000000  0.57   \n",
       "37        0.60                  0.63             1.10         5.000000  0.82   \n",
       "38        3.75                  0.24             1.95         4.500000  1.04   \n",
       "39        1.10                  0.52             2.29        11.750000  0.57   \n",
       "40        2.64                  0.28             1.37         3.700000  1.18   \n",
       "41        2.04                  0.39             2.08         2.700000  0.86   \n",
       "42        1.94                  0.30             1.46         2.620000  1.23   \n",
       "43        1.30                  0.55             0.42         3.170000  1.02   \n",
       "44        0.80                  0.47             1.02         4.400000  0.91   \n",
       "\n",
       "    od280/od315_of_diluted_wines  proline  actual_class  predicted_class  \n",
       "0                           3.36    845.0             0                0  \n",
       "1                           3.33   1080.0             0                0  \n",
       "2                           2.31    600.0             2                2  \n",
       "3                           2.71   1285.0             0                0  \n",
       "4                           3.48    510.0             1                1  \n",
       "5                           2.65   1280.0             0                0  \n",
       "6                           3.05    564.0             1                1  \n",
       "7                           1.56    750.0             2                2  \n",
       "8                           3.26    680.0             1                1  \n",
       "9                           2.47    780.0             2                2  \n",
       "10                          3.82    845.0             0                0  \n",
       "11                          1.30    500.0             2                2  \n",
       "12                          3.00   1035.0             0                0  \n",
       "13                          2.12    372.0             1                1  \n",
       "14                          2.88   1310.0             0                0  \n",
       "15                          2.78    325.0             1                1  \n",
       "16                          2.31    434.0             1                1  \n",
       "17                          2.72    630.0             1                1  \n",
       "18                          3.55   1045.0             0                0  \n",
       "19                          3.19    385.0             1                1  \n",
       "20                          2.82   1680.0             0                0  \n",
       "21                          3.18    502.0             1                1  \n",
       "22                          1.67    680.0             1                1  \n",
       "23                          1.92    630.0             2                2  \n",
       "24                          1.63    470.0             2                2  \n",
       "25                          1.68    615.0             2                2  \n",
       "26                          2.96    345.0             1                1  \n",
       "27                          2.30    678.0             1                1  \n",
       "28                          2.27    480.0             1                1  \n",
       "29                          3.03   1120.0             0                0  \n",
       "30                          3.59   1035.0             0                0  \n",
       "31                          2.78    342.0             1                1  \n",
       "32                          1.68    830.0             2                2  \n",
       "33                          2.88   1515.0             0                0  \n",
       "34                          2.90   1320.0             0                0  \n",
       "35                          3.56   1095.0             0                0  \n",
       "36                          1.96    660.0             2                2  \n",
       "37                          1.69    515.0             2                2  \n",
       "38                          2.77    660.0             1                1  \n",
       "39                          1.78    620.0             2                2  \n",
       "40                          2.69   1020.0             0                0  \n",
       "41                          3.02    312.0             1                1  \n",
       "42                          3.16    450.0             1                1  \n",
       "43                          1.93    750.0             1                1  \n",
       "44                          2.05    550.0             2                2  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4d9e8",
   "metadata": {},
   "source": [
    "# Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e38d620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run valuable-ape-972 at: http://127.0.0.1:5000/#/experiments/545408099770630109/runs/d8c5179bb11a489eaf24b3a0785322d1\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/545408099770630109\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine_rf_experiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    #log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    #log accuracy metrics\n",
    "    mlflow.log_metric(\"accuracy\", 1.0) # Convert to list for logging\n",
    "    \n",
    "    #Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Model Training\", \"Using a model = RandomForestClassifier\")\n",
    "    \n",
    "    ## Infer the model signature\n",
    "    signature = infer_signature(X_train, rf.predict(X_train))\n",
    "    \n",
    "    #log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        rf,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        #registered_model_name=\"WineQualityRandomForestModel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe87b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "147dc599",
   "metadata": {},
   "source": [
    "## Inferencing from model version from registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5844d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "model_name = \"WineQualityRandomForestModel\"\n",
    "model_version = 5\n",
    "\n",
    "model_uri  = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21adf373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models:/WineQualityRandomForestModel/5'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1caad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17e350f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 1, 0, 1, 2, 1, 2, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 2, 2, 2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 2, 2, 1, 2, 0, 1, 1, 1,\n",
       "       2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d2bcd",
   "metadata": {},
   "source": [
    "## Note: *u only need to register after validating the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac8305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
